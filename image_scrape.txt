# compare with mojo

#!/usr/bin/perl
use strict;
use warnings;
use WWW::Mechanize;
use HTML::TreeBuilder;
use URI::URL;

# URL of the webpage to scrape
my $url = 'https://example.com';

# Directory to save downloaded images
my $download_dir = 'downloaded_images';

# Create a new mechanize object
my $mech = WWW::Mechanize->new();

# Get the webpage content
$mech->get($url);

# Check if the page was retrieved successfully
if ($mech->success()) {
    my $content = $mech->content();

    # Create an HTML tree from the page content
    my $tree = HTML::TreeBuilder->new_from_content($content);

    # Find all image tags
    my @img_tags = $tree->look_down('_tag', 'img');

    # Create download directory if it doesn't exist
    unless (-e $download_dir) {
        mkdir $download_dir or die "Unable to create directory: $!";
    }

    # Download each image
    foreach my $img_tag (@img_tags) {
        my $img_url = $img_tag->attr('src');

        # Make the URL absolute if it's a relative URL
        $img_url = url($img_url, $mech->uri)->abs;

        # Extract the image filename
        my ($img_filename) = $img_url =~ m/\/([^\/]+)$/;
        my $img_path = "$download_dir/$img_filename";

        # Download the image
        $mech->get($img_url, ':content_file' => $img_path);
        print "Downloaded: $img_url\n";
    }

    # Clean up
    $tree->delete();
} else {
    print "Failed"
}



Replace the $url variable with the URL of the webpage you want to scrape images from. The script will download the images to the specified directory ($download_dir).
Note that the script assumes that the image URLs are contained in src attributes of img tags.
Depending on the structure of the webpage, you may need to adjust the script to match the HTML structure of the target site.
